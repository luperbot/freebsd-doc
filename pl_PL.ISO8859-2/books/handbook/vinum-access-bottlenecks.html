<?xml version="1.0" encoding="iso-8859-2" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=iso-8859-2" /><title>19.3. Access Bottlenecks</title><link rel="stylesheet" type="text/css" href="docbook.css" /><link rev="made" href="mailto:doc@FreeBSD.org" /><meta name="generator" content="DocBook XSL Stylesheets V1.78.1" /><link rel="home" href="index.html" title="Podrêcznik FreeBSD" /><link rel="up" href="vinum-vinum.html" title="Rozdzia³ 19. The Vinum Volume Manager" /><link rel="prev" href="vinum-intro.html" title="19.2. Disks Are Too Small" /><link rel="next" href="vinum-data-integrity.html" title="19.4. Data Integrity" /><link rel="copyright" href="legalnotice.html" title="Informacja Prawna" /><script xmlns="" type="text/javascript" src="/layout/js/google.js"></script></head><body><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">19.3. Access Bottlenecks</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="vinum-intro.html">Poprzedni</a> </td><th width="60%" align="center">Rozdzia³ 19. The Vinum Volume Manager</th><td width="20%" align="right"> <a accesskey="n" href="vinum-data-integrity.html">Nastêpny</a></td></tr></table><hr /></div><div class="sect1"><div xmlns="" class="titlepage"><div><div><h2 xmlns="http://www.w3.org/1999/xhtml" class="title" style="clear: both"><a id="vinum-access-bottlenecks"></a>19.3. Access Bottlenecks</h2></div></div></div><p>Modern systems frequently need to access data in a highly
      concurrent manner.  For example, large FTP or HTTP servers can
      maintain thousands of concurrent sessions and have multiple
      100 Mbit/s connections to the outside world, well beyond
      the sustained transfer rate of most disks.</p><p>Current disk drives can transfer data sequentially at up to
      70 MB/s, but this value is of little importance in an
      environment where many independent processes access a drive,
      where they may achieve only a fraction of these values.  In such
      cases it is more interesting to view the problem from the
      viewpoint of the disk subsystem: the important parameter is the
      load that a transfer places on the subsystem, in other words the
      time for which a transfer occupies the drives involved in the
      transfer.</p><p>In any disk transfer, the drive must first position the
      heads, wait for the first sector to pass under the read head,
      and then perform the transfer.  These actions can be considered
      to be atomic: it does not make any sense to interrupt
      them.</p><p><a id="vinum-latency"></a> Consider a typical transfer of
      about 10 kB: the current generation of high-performance
      disks can position the heads in an average of 3.5 ms.  The
      fastest drives spin at 15,000 rpm, so the average
      rotational latency (half a revolution) is 2 ms.  At
      70 MB/s, the transfer itself takes about 150 ½´/4s,
      almost nothing compared to the positioning time.  In such a
      case, the effective transfer rate drops to a little over
      1 MB/s and is clearly highly dependent on the transfer
      size.</p><p>The traditional and obvious solution to this bottleneck is
      <span class="quote">"<span class="quote">more spindles</span>"</span>: rather than using one large disk,
      it uses several smaller disks with the same aggregate storage
      space.  Each disk is capable of positioning and transferring
      independently, so the effective throughput increases by a factor
      close to the number of disks used.
    </p><p>The exact throughput improvement is, of course, smaller than
      the number of disks involved: although each drive is capable of
      transferring in parallel, there is no way to ensure that the
      requests are evenly distributed across the drives.  Inevitably
      the load on one drive will be higher than on another.</p><a id="idp89610960" class="indexterm"></a><a id="idp89611728" class="indexterm"></a><p>The evenness of the load on the disks is strongly dependent
      on the way the data is shared across the drives.  In the
      following discussion, it is convenient to think of the disk
      storage as a large number of data sectors which are addressable
      by number, rather like the pages in a book.  The most obvious
      method is to divide the virtual disk into groups of consecutive
      sectors the size of the individual physical disks and store them
      in this manner, rather like taking a large book and tearing it
      into smaller sections.  This method is called
      <span class="emphasis"><em>concatenation</em></span> and has the advantage that
      the disks are not required to have any specific size
      relationships.  It works well when the access to the virtual
      disk is spread evenly about its address space.  When access is
      concentrated on a smaller area, the improvement is less marked.
      <a class="xref" href="vinum-access-bottlenecks.html#vinum-concat" title="Rysunek 19.1. Concatenated Organization">Rysunek 19.1, "Concatenated Organization"</a> illustrates the sequence in which
      storage units are allocated in a concatenated
      organization.</p><p>
      </p><div class="figure"><a id="vinum-concat"></a><div class="figure-title">Rysunek 19.1. Concatenated Organization</div><div class="figure-contents"><div class="mediaobject"><img src="vinum/vinum-concat.png" alt="Concatenated Organization" /></div></div></div><p><br class="figure-break" />
    </p><a id="idp89615952" class="indexterm"></a><a id="idp89616720" class="indexterm"></a><a id="idp89618000" class="indexterm"></a><p>An alternative mapping is to divide the address space into
      smaller, equal-sized components and store them sequentially on
      different devices.  For example, the first 256 sectors may be
      stored on the first disk, the next 256 sectors on the next disk
      and so on.  After filling the last disk, the process repeats
      until the disks are full.  This mapping is called
      <span class="emphasis"><em>striping</em></span> or <acronym class="acronym">RAID-0</acronym>

    <a href="#ftn.idp89619792" class="footnote" id="idp89619792"><sup class="footnote">[13]</sup></a>.

    Striping requires somewhat more effort to locate the data, and it
    can cause additional I/O load where a transfer is spread over
    multiple disks, but it can also provide a more constant load
    across the disks.  <a class="xref" href="vinum-access-bottlenecks.html#vinum-striped" title="Rysunek 19.2. Striped Organization">Rysunek 19.2, "Striped Organization"</a> illustrates the
    sequence in which storage units are allocated in a striped
    organization.</p><p>
      </p><div class="figure"><a id="vinum-striped"></a><div class="figure-title">Rysunek 19.2. Striped Organization</div><div class="figure-contents"><div class="mediaobject"><img src="vinum/vinum-striped.png" alt="Striped Organization" /></div></div></div><p><br class="figure-break" />
    </p><div class="footnotes"><br /><hr class="footnote-hr" /><div id="ftn.idp89619792" class="footnote"><p><a href="#idp89619792" class="para"><sup class="para">[13] </sup></a><acronym class="acronym">RAID</acronym> stands for <span class="emphasis"><em>Redundant
      Array of Inexpensive Disks</em></span> and offers various forms
      of fault tolerance, though the latter term is somewhat
      misleading: it provides no redundancy.</p></div></div></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="vinum-intro.html">Poprzedni</a> </td><td width="20%" align="center"><a accesskey="u" href="vinum-vinum.html">Pocz±tek rozdzia³u</a></td><td width="40%" align="right"> <a accesskey="n" href="vinum-data-integrity.html">Nastêpny</a></td></tr><tr><td width="40%" align="left" valign="top">19.2. Disks Are Too Small </td><td width="20%" align="center"><a accesskey="h" href="index.html">Spis tre¶ci</a></td><td width="40%" align="right" valign="top"> 19.4. Data Integrity</td></tr></table></div><p xmlns="" align="center"><small>All FreeBSD documents are available for download
    at <a href="http://ftp.FreeBSD.org/pub/FreeBSD/doc/">http://ftp.FreeBSD.org/pub/FreeBSD/doc/</a></small></p><p xmlns="" align="center"><small>Questions that are not answered by the
    <a href="http://www.FreeBSD.org/docs.html">documentation</a> may be
    sent to &lt;<a href="mailto:freebsd-questions@FreeBSD.org">freebsd-questions@FreeBSD.org</a>&gt;.<br />
    Send questions about this document to &lt;<a href="mailto:freebsd-doc@FreeBSD.org">freebsd-doc@FreeBSD.org</a>&gt;.</small></p></body></html>