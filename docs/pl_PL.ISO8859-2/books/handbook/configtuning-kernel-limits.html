<?xml version="1.0" encoding="iso-8859-2" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=iso-8859-2" /><title>11.13. Tuning Kernel Limits</title><link rel="stylesheet" type="text/css" href="docbook.css" /><link rev="made" href="mailto:doc@FreeBSD.org" /><meta name="generator" content="DocBook XSL Stylesheets V1.78.1" /><link rel="home" href="index.html" title="Podrêcznik FreeBSD" /><link rel="up" href="config-tuning.html" title="Rozdzia³ 11. Configuration and Tuning" /><link rel="prev" href="configtuning-disk.html" title="11.12. Tuning Disks" /><link rel="next" href="adding-swap-space.html" title="11.14. Adding Swap Space" /><link rel="copyright" href="legalnotice.html" title="Informacja Prawna" /><script xmlns="" type="text/javascript" src="/layout/js/google.js"></script></head><body><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">11.13. Tuning Kernel Limits</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="configtuning-disk.html">Poprzedni</a> </td><th width="60%" align="center">Rozdzia³ 11. Configuration and Tuning</th><td width="20%" align="right"> <a accesskey="n" href="adding-swap-space.html">Nastêpny</a></td></tr></table><hr /></div><div class="sect1"><div xmlns="" class="titlepage"><div><div><h2 xmlns="http://www.w3.org/1999/xhtml" class="title" style="clear: both"><a id="configtuning-kernel-limits"></a>11.13. Tuning Kernel Limits</h2></div></div></div><a id="idp84590800" class="indexterm"></a><div class="sect2"><div xmlns="" class="titlepage"><div><div><h3 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="file-process-limits"></a>11.13.1. File/Process Limits</h3></div></div></div><div class="sect3"><div xmlns="" class="titlepage"><div><div><h4 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="kern-maxfiles"></a>11.13.1.1. <code class="varname">kern.maxfiles</code></h4></div></div></div><a id="idp84597840" class="indexterm"></a><p><code class="varname">kern.maxfiles</code> can be raised or
	  lowered based upon your system requirements.  This variable
	  indicates the maximum number of file descriptors on your
	  system.  When the file descriptor table is full,
	  <span class="errorname">file: table is full</span> will show up repeatedly
	  in the system message buffer, which can be viewed with the
	  <code class="command">dmesg</code> command.</p><p>Each open file, socket, or fifo uses one file
	  descriptor.  A large-scale production server may easily
	  require many thousands of file descriptors, depending on the
	  kind and number of services running concurrently.</p><p>In older FreeBSD releases, <code class="varname">kern.maxfile</code>'s default
          value is derived from the <code class="option">maxusers</code> option in your
          kernel configuration file.  <code class="varname">kern.maxfiles</code> grows
          proportionally to the value of <code class="option">maxusers</code>.  When
          compiling a custom kernel, it is a good idea to set this kernel
          configuration option according to the uses of your system.  From
          this number, the kernel is given most of its pre-defined limits.
          Even though a production machine may not actually have 256 users
          connected at once, the resources needed may be similar to a
          high-scale web server.</p><p>As of FreeBSD 4.5, <code class="varname">kern.maxusers</code> is
          automatically sized at boot based on the amount of memory available
          in the system, and may be determined at run-time by inspecting the
          value of the read-only <code class="varname">kern.maxusers</code> sysctl.
          Some sites will require larger or smaller values of
          <code class="varname">kern.maxusers</code> and may set it as a loader tunable;
          values of 64, 128, and 256 are not uncommon.  We do not recommend
          going above 256 unless you need a huge number of file descriptors;
          many of the tunable values set to their defaults by
          <code class="varname">kern.maxusers</code> may be individually overridden at
          boot-time or run-time in <code class="filename">/boot/loader.conf</code> (see
          the <a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=loader.conf&amp;sektion=5"><span class="citerefentry"><span class="refentrytitle">loader.conf</span>(5)</span></a> man page or the
          <code class="filename">/boot/defaults/loader.conf</code> file for some hints)
          or as described elsewhere in this document.  Systems older than
          FreeBSD 4.4 must set this value via the kernel <a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=config&amp;sektion=8"><span class="citerefentry"><span class="refentrytitle">config</span>(8)</span></a>
          option <code class="option">maxusers</code> instead.</p><p>In older releases, the system will auto-tune
	  <code class="literal">maxusers</code> for you if you explicitly set it to
	  <code class="literal">0</code><a href="#ftn.idp84612176" class="footnote" id="idp84612176"><sup class="footnote">[5]</sup></a>.  When setting this option, you will want to set
	  <code class="literal">maxusers</code> to at least 4, especially if you are
	  using the X Window System or compiling software.  The reason is that
	  the most important table set by <code class="literal">maxusers</code> is the
	  maximum number of processes,  which is set to <code class="literal">20 + 16 *
	  maxusers</code>, so if you set <code class="literal">maxusers</code> to 1,
	  then you can only have 36 simultaneous processes, including the 18
	  or so that the system starts up at boot time and the 15 or so you
	  will probably create when you start the X Window System.  Even a
	  simple task like reading a manual page will start up nine
	  processes to filter, decompress, and view it.  Setting
	  <code class="literal">maxusers</code> to 64 will allow you to have up to 1044
	  simultaneous processes, which should be enough for nearly all uses.
	  If, however, you see the dreaded <span class="errortype">proc table
	  full</span> error when trying to start another program, or are
	  running a server with a large number of simultaneous users (like
	  <code class="systemitem">ftp.FreeBSD.org</code>), you can always
	  increase the number and rebuild.</p><div xmlns="" class="note"><h3 class="admontitle">Uwaga: </h3><p xmlns="http://www.w3.org/1999/xhtml"><code class="literal">maxusers</code> does <span class="emphasis"><em>not</em></span>
	    limit the number of users which can log into your machine.  It
	    simply sets various table sizes to reasonable values considering
	    the maximum number of users you will likely have on your system
	    and how many processes each of them will be running.  One keyword
	    which <span class="emphasis"><em>does</em></span> limit the number of simultaneous
	    remote logins and X terminal windows is <a class="link" href="kernelconfig-config.html#kernelconfig-ptys"><code class="literal">pseudo-device pty
	    16</code></a>.  With FreeBSD 5.X, you do not have to
	    worry about this number since the <a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=pty&amp;sektion=4"><span class="citerefentry"><span class="refentrytitle">pty</span>(4)</span></a> driver is
	    <span class="quote">"<span class="quote">auto-cloning</span>"</span>; you simply use the line
	    <code class="literal">device pty</code> in your configuration file.</p></div></div><div class="sect3"><div xmlns="" class="titlepage"><div><div><h4 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="idp84620624"></a>11.13.1.2. <code class="varname">kern.ipc.somaxconn</code></h4></div></div></div><a id="idp84621392" class="indexterm"></a><p>The <code class="varname">kern.ipc.somaxconn</code> sysctl variable
	  limits the size of the listen queue for accepting new TCP
	  connections.  The default value of <code class="literal">128</code> is
	  typically too low for robust handling of new connections in a
	  heavily loaded web server environment.  For such environments, it
	  is recommended to increase this value to <code class="literal">1024</code> or
	  higher.  The service daemon may itself limit the listen queue size
	  (e.g. <a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=sendmail&amp;sektion=8"><span class="citerefentry"><span class="refentrytitle">sendmail</span>(8)</span></a>, or <span class="application">Apache</span>) but
	  will often have a directive in its configuration file to adjust
	  the queue size.  Large listen queues also do a better job of
	  avoiding Denial of Service (<abbr class="abbrev">DoS</abbr>) attacks.</p></div></div><div class="sect2"><div xmlns="" class="titlepage"><div><div><h3 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="nmbclusters"></a>11.13.2. Network Limits</h3></div></div></div><p>The <code class="literal">NMBCLUSTERS</code> kernel configuration
	option dictates the amount of network Mbufs available to the
	system.  A heavily-trafficked server with a low number of Mbufs
	will hinder FreeBSD's ability.  Each cluster represents
	approximately 2 K of memory, so a value of 1024 represents 2
	megabytes of kernel memory reserved for network buffers.  A
	simple calculation can be done to figure out how many are
	needed.  If you have a web server which maxes out at 1000
	simultaneous connections, and each connection eats a 16 K receive
	and 16 K send buffer, you need approximately 32 MB worth of
	network buffers to cover the web server.  A good rule of thumb is
	to multiply by 2, so 2x32 MB / 2 KB =
	64 MB / 2 kB = 32768.  We recommend
	values between 4096 and 32768 for machines with greater amounts
	of memory.  Under no circumstances should you specify an
	arbitrarily high value for this parameter as it could lead to a
	boot time crash.  The <code class="option">-m</code> option to
	<a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=netstat&amp;sektion=1"><span class="citerefentry"><span class="refentrytitle">netstat</span>(1)</span></a> may be used to observe network cluster
	use.</p><p><code class="varname">kern.ipc.nmbclusters</code> loader tunable should
        be used to tune this at boot time.  Only older versions of FreeBSD
        will require you to use the <code class="literal">NMBCLUSTERS</code> kernel
        <a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=config&amp;sektion=8"><span class="citerefentry"><span class="refentrytitle">config</span>(8)</span></a> option.</p><p>For busy servers that make extensive use of the
	<a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=sendfile&amp;sektion=2"><span class="citerefentry"><span class="refentrytitle">sendfile</span>(2)</span></a> system call, it may be necessary to increase
	the number of <a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=sendfile&amp;sektion=2"><span class="citerefentry"><span class="refentrytitle">sendfile</span>(2)</span></a> buffers via the
	<code class="literal">NSFBUFS</code> kernel configuration option or by
	setting its value in <code class="filename">/boot/loader.conf</code>
	(see <a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=loader&amp;sektion=8"><span class="citerefentry"><span class="refentrytitle">loader</span>(8)</span></a> for details).  A common indicator that
	this parameter needs to be adjusted is when processes are seen
	in the <code class="literal">sfbufa</code> state.  The sysctl
	variable <code class="varname">kern.ipc.nsfbufs</code> is a read-only
	glimpse at the kernel configured variable.  This parameter
	nominally scales with <code class="varname">kern.maxusers</code>,
	however it may be necessary to tune accordingly.</p><div xmlns="" class="important"><h3 class="admontitle">Wa¿ne: </h3><p xmlns="http://www.w3.org/1999/xhtml">Even though a socket has been marked as non-blocking,
	  calling <a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=sendfile&amp;sektion=2"><span class="citerefentry"><span class="refentrytitle">sendfile</span>(2)</span></a> on the non-blocking socket may
	  result in the <a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=sendfile&amp;sektion=2"><span class="citerefentry"><span class="refentrytitle">sendfile</span>(2)</span></a> call blocking until enough
	  <code class="literal">struct sf_buf</code>'s are made
	  available.</p></div><div class="sect3"><div xmlns="" class="titlepage"><div><div><h4 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="idp84650192"></a>11.13.2.1. <code class="varname">net.inet.ip.portrange.*</code></h4></div></div></div><a id="idp84650960" class="indexterm"></a><p>The <code class="varname">net.inet.ip.portrange.*</code> sysctl
	  variables control the port number ranges automatically bound to TCP
	  and UDP sockets.  There are three ranges: a low range, a default
	  range, and a high range.  Most network programs use the default
	  range which is controlled by the
	  <code class="varname">net.inet.ip.portrange.first</code> and
	  <code class="varname">net.inet.ip.portrange.last</code>, which default to
	  1024 and 5000, respectively.  Bound port ranges are used  for
	  outgoing connections, and it is possible to run the system out of
	  ports under certain circumstances.  This most commonly occurs
	  when you are running a heavily loaded web proxy.  The port range
	  is not an issue when running servers which handle mainly incoming
	  connections, such as a normal web server, or has a limited number
	  of outgoing connections, such as a mail relay.  For situations
	  where you may run yourself out of ports, it is recommended to
	  increase <code class="varname">net.inet.ip.portrange.last</code> modestly.
	  A value of <code class="literal">10000</code>, <code class="literal">20000</code> or
	  <code class="literal">30000</code> may be reasonable.  You should also
	  consider firewall effects when changing the port range.  Some
	  firewalls may block large ranges of ports (usually low-numbered
	  ports) and expect systems to use higher ranges of ports for
	  outgoing connections - for this reason it is not recommended that
	  <code class="varname">net.inet.ip.portrange.first</code> be lowered.</p></div><div class="sect3"><div xmlns="" class="titlepage"><div><div><h4 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="idp84655440"></a>11.13.2.2. TCP Bandwidth Delay Product</h4></div></div></div><a id="idp84656080" class="indexterm"></a><p>The TCP Bandwidth Delay Product Limiting is similar to
	  TCP/Vegas in NetBSD.  It can be
	  enabled by setting <code class="varname">net.inet.tcp.inflight.enable</code>
	  sysctl variable to <code class="literal">1</code>.  The system will attempt
	  to calculate the bandwidth delay product for each connection and
	  limit the amount of data queued to the network to just the amount
	  required to maintain optimum throughput.</p><p>This feature is useful if you are serving data over modems,
	  Gigabit Ethernet, or even high speed WAN links (or any other link
	  with a high bandwidth delay product), especially if you are also
	  using window scaling or have configured a large send window.  If
	  you enable this option, you should also be sure to set
	  <code class="varname">net.inet.tcp.inflight.debug</code> to
	  <code class="literal">0</code> (disable debugging), and for production use
	  setting <code class="varname">net.inet.tcp.inflight.min</code> to at least
	  <code class="literal">6144</code> may be beneficial.  However, note that
	  setting high minimums may effectively disable bandwidth limiting
	  depending on the link.  The limiting feature reduces the amount of
	  data built up in intermediate route and switch packet queues as
	  well as reduces the amount of data built up in the local host's
	  interface queue.  With fewer packets queued up, interactive
	  connections, especially over slow modems, will also be able to
	  operate with lower <span class="emphasis"><em>Round Trip Times</em></span>.  However,
	  note that this feature only effects data transmission (uploading
	  / server side).  It has no effect on data reception (downloading).
	</p><p>Adjusting <code class="varname">net.inet.tcp.inflight.stab</code> is
	  <span class="emphasis"><em>not</em></span> recommended.  This parameter defaults to
	  20, representing 2 maximal packets added to the bandwidth delay
	  product window calculation.  The additional window is required to
	  stabilize the algorithm and improve responsiveness to changing
	  conditions, but it can also result in higher ping times over slow
	  links (though still much lower than you would get without the
	  inflight algorithm).  In such cases, you may wish to try reducing
	  this parameter to 15, 10, or 5; and may also have to reduce
	  <code class="varname">net.inet.tcp.inflight.min</code> (for example, to
	  3500) to get the desired effect.  Reducing these parameters
	  should be done as a last resort only.</p></div></div><div class="sect2"><div xmlns="" class="titlepage"><div><div><h3 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="idp84667088"></a>11.13.3. Virtual Memory</h3></div></div></div><div class="sect3"><div xmlns="" class="titlepage"><div><div><h4 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="idp84667728"></a>11.13.3.1. <code class="varname">kern.maxvnodes</code></h4></div></div></div><p>A vnode is the internal representation of a file or
          directory.  So increasing the number of vnodes available to
          the operating system cuts down on disk I/O.  Normally this
          is handled by the operating system and does not need to be
          changed.  In some cases where disk I/O is a bottleneck and
          the system is running out of vnodes, this setting will need
          to be increased.  The amount of inactive and free RAM will
          need to be taken into account.</p><p>To see the current number of vnodes in use:</p><pre class="programlisting"><code class="prompt">#</code> sysctl vfs.numvnodes
vfs.numvnodes: 91349</pre><p>To see the maximum vnodes:</p><pre class="programlisting"><code class="prompt">#</code> sysctl kern.maxvnodes
kern.maxvnodes: 100000</pre><p>If the current vnode usage is near the maximum, increasing
          <code class="varname">kern.maxvnodes</code> by a value of 1,000 is
          probably a good idea.  Keep an eye on the number of
          <code class="varname">vfs.numvnodes</code>.  If it climbs up to the
          maximum again, <code class="varname">kern.maxvnodes</code> will need to
          be increased further.  A shift in your memory usage as
          reported by <a class="citerefentry" href="http://www.FreeBSD.org/cgi/man.cgi?query=top&amp;sektion=1"><span class="citerefentry"><span class="refentrytitle">top</span>(1)</span></a> should be visible.  More memory should
          be active.</p></div></div><div class="footnotes"><br /><hr class="footnote-hr" /><div id="ftn.idp84612176" class="footnote"><p><a href="#idp84612176" class="para"><sup class="para">[5] </sup></a>The auto-tuning algorithm sets
	      <code class="literal">maxusers</code> equal to the amount of memory in the
	      system, with a minimum of 32, and a maximum of 384.</p></div></div></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="configtuning-disk.html">Poprzedni</a> </td><td width="20%" align="center"><a accesskey="u" href="config-tuning.html">Pocz±tek rozdzia³u</a></td><td width="40%" align="right"> <a accesskey="n" href="adding-swap-space.html">Nastêpny</a></td></tr><tr><td width="40%" align="left" valign="top">11.12. Tuning Disks </td><td width="20%" align="center"><a accesskey="h" href="index.html">Spis tre¶ci</a></td><td width="40%" align="right" valign="top"> 11.14. Adding Swap Space</td></tr></table></div><p xmlns="" align="center"><small>All FreeBSD documents are available for download
    at <a href="http://ftp.FreeBSD.org/pub/FreeBSD/doc/">http://ftp.FreeBSD.org/pub/FreeBSD/doc/</a></small></p><p xmlns="" align="center"><small>Questions that are not answered by the
    <a href="http://www.FreeBSD.org/docs.html">documentation</a> may be
    sent to &lt;<a href="mailto:freebsd-questions@FreeBSD.org">freebsd-questions@FreeBSD.org</a>&gt;.<br />
    Send questions about this document to &lt;<a href="mailto:freebsd-doc@FreeBSD.org">freebsd-doc@FreeBSD.org</a>&gt;.</small></p></body></html>